&emsp;&emsp;**Hierarchical World Models.**
&emsp;&emsp;Hierarchical systems play a critical role in building effective world models, as they allow agents to reason across multiple layers of abstraction. However, designing hierarchical models is inherently challenging: separating low-level and high-level dynamics is difficult, and coordinating interactions across layers adds further complexity. While existing studies primarily emphasize model design [@gumbsch2023learning;@lecun2022path;@wang2025dmwm;@xing2025critiques], their validation in complex real-world environments remains limited.

&emsp;&emsp;**Causality** is a fundamental principle for understanding and modeling the world, describing how events or factors influence outcomes and enabling reasoning about future consequences. It is the key to the world model and agents to allow them to interact with the world, which is inline with the human cognition. Richens *et al.* [@richens2024robust] indicate that learning a causal model is the key to ensure the generalization ability to new domains. Wang *et al.* [@wang2022causal;@tomar2021model] learn a causal dynamics model by removing unnecessary dependencies for tasks, which however are constrained to specific tasks. Gupta *et al.* [@gupta2024essential] argue that conventional theory-driven approaches to causal modeling, such as those in [@stuart2010matching;@chernozhukov2018double], are insufficient for world models that aim for generalizable understanding. These methods rely on predefined variables and case-specific theoretical properties. In the real world, sensory inputs are complex, often unstructured, and key theoretical properties, such as identifiability, may not hold.

&emsp;&emsp;**Resource-Constrained Deployment.**
&emsp;&emsp;Current world models, particularly those based on video generation, are computationally intensive and contain hundreds of millions of parameters, which limits their feasibility for real-world robotic deployment and on-device inference. To enable practical applications, designing lightweight and efficient world models has become increasingly important. Quantization and model compression techniques offer promising directions for reducing memory and computational costs, and have been extensively explored in related domains [@polino2018model;@gholami2022survey;@shang2023post;@li2021lightweight], providing both direct solutions and inspiration for future lightweight world model architectures.

&emsp;&emsp;**Fairness and Security.**
&emsp;&emsp;As world models become integral to embodied agents and decision-making systems, ensuring their ethical alignment and fairness is critical. Unlike conventional vision or language models, world models directly influence how autonomous agents perceive, reason, and act within real environments, which amplifies the consequences of biased or unsafe representations. To handle this, emerging research explores bias auditing, fairness-aware training, and safety-constrained learning objectives to prevent harmful behaviors and unintended policy generalization.

&emsp;&emsp;Furthermore, deep models are known to be vulnerable to adversarial attacks, which can compromise performance by introducing imperceptible perturbations to inputs [@szegedy2013intriguing;@zhang2024universal], modifying model parameters [@ren2023dimension;@park2022blurs], or even exploiting hardware-level weaknesses [@cojocar2020we;@jattke2024zenhammer].
&emsp;&emsp;These vulnerabilities raise serious concerns regarding the security and reliability of world models, especially when deployed in safety-critical domains.
&emsp;&emsp;To date, systematic studies on the robustness and security of world models remain limited, underscoring an urgent need for dedicated research into adversarial resilience, trustworthy deployment, and secure model adaptation.

&emsp;&emsp;**Evaluation Protocols.**
&emsp;&emsp;Current evaluation practices for world models are fragmented and only loosely aligned with their intended capabilities, often relying on task-specific or proxy metrics and partial human validation [@liao2025genie]. There is a pressing need for standardized benchmarks and unified evaluation frameworks that can comprehensively assess world model competence across multiple dimensions, including visual fidelity, policy success, causal consistency, physical plausibility, generalization, and long-horizon reasoning.

&emsp;&emsp;**Beyond Human Intelligence.**
&emsp;&emsp;Insights from human cognition have profoundly influenced the design of robotic and world modeling systems [@lecun2022path;@gumbsch2023learning;@bjorck2025gr00t;@wang2025dmwm]. However, the completeness of the world extends beyond human cognition, which is bounded by partial observation, finite memory, limited attention, and inherent heuristic biases. World models are therefore expected to transcend human cognitive bounds, providing a deeper and more systematic understanding of complex environments.